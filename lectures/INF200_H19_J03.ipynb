{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF200 Lecture No J03\n",
    "### Hans Ekkehard Plesser / NMBU\n",
    "### 4 June 2020\n",
    "\n",
    "## Today's topics\n",
    "\n",
    "- More on testing\n",
    "    - unit/integration/acceptance/regression testing\n",
    "    - file layout\n",
    "    - approximate comparisons\n",
    "    - mocking\n",
    "    - fixtures\n",
    "- Statistical tests and random selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on testing\n",
    "\n",
    "### Levels of testing\n",
    "\n",
    "- *unit tests* are tests of small parts of code\n",
    "    - test individual methods\n",
    "- *integration tests* test that the parts of a larger project work together\n",
    "    - test that class instances behave as expected\n",
    "    - expect that a class, e.g., representing a landscape cell, properly manages animals\n",
    "- *acceptance tests* test that the software as a whole\n",
    "    - `check_sim.py`\n",
    "    - `test_biosim_interface.py`\n",
    "    - similar simulations, e.g., with parameter modifications\n",
    "        - different islands and initial populations\n",
    "        - parameter choices preventing birth, death, eating, movement, ...\n",
    "- *regression tests* are added when a bug is discovered\n",
    "    - the test reproduces the bug\n",
    "    - when the bug is fixed, the test passes\n",
    "    - we keep the test, in case we should re-introduce the bug by a later change (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File layout\n",
    "\n",
    "- You should write different test modules (files) to keep everything neat and organized\n",
    "- Rule of thumb: One test module for each module in your package\n",
    "    - `animals.py` ---> `test_animals.py`\n",
    "    - `landscape.py` ---> `test_landscape.py`\n",
    "    - ...\n",
    "- Each individual test function should be given a descriptive name\n",
    "    - When a test fails, the first thing you read is the name\n",
    "        - Should describe what was tested and failed\n",
    "    - Should write a docstring to further explain the test\n",
    "    \n",
    "#### Placement of tests\n",
    "\n",
    "- Two alternatives, no definite \"best\" solution\n",
    "- See https://docs.python-guide.org/writing/structure/ for a discussion on structure\n",
    "- See course repository `examples`\n",
    "- Both variants can be run in the same way from PyCharm by adding a suitable PyTest configuration\n",
    "- **We will use variant 1**\n",
    "\n",
    "##### Variant 1: tests parallel to code directory\n",
    "```\n",
    "chutes_project/\n",
    "   chutes/\n",
    "      __init__.py\n",
    "      board.py\n",
    "      ...\n",
    "   examples/\n",
    "   tests/\n",
    "      test_board.py\n",
    "   setup.py\n",
    "```\n",
    "- `tests` is a directory \"parallel\" to `chutes` code directory\n",
    "- `tests` is *not* a package\n",
    "- Test files use absolute imports\n",
    "```python\n",
    "from chutes.board import Board\n",
    "```\n",
    "- PyTest configuration in PyCharm should cover `tests` directory\n",
    "- Tests are not installed when Chutes is installed on a computer (details later)\n",
    "    - `setup.py` specificies only `chutes` as installable package\n",
    "    ```\n",
    "          packages=['chutes'],\n",
    "    ```\n",
    "    - `Manifest.in` must also specify `tests` as directory to include in distribution\n",
    "    ```\n",
    "    recursive-include tests *.py\n",
    "    ```\n",
    "\n",
    "\n",
    "##### Variant 2: tests in code directory\n",
    "```\n",
    "chutes_project_alt/\n",
    "   chutes/\n",
    "      __init__.py\n",
    "      board.py\n",
    "      ...\n",
    "      tests/\n",
    "         __init__.py\n",
    "         test_board.py\n",
    "   examples/\n",
    "   setup.py\n",
    "```\n",
    "- `tests` is subdirectory of `chutes` code directory\n",
    "- `tests` is a package (contains `__init__.py`)\n",
    "- Test files use relative imports\n",
    "```python\n",
    "from ..board import Board\n",
    "```\n",
    "- PyTest configuration in PyCharm should cover `chutes/tests` directory\n",
    "- Tests are installed when Chutes is installed on a computer (details later)\n",
    "    - `setup.py` specificies `tests` as installable package\n",
    "    ```\n",
    "          packages=['chutes', 'chutes.tests'],\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "### Approximate comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if two numbers are equal to within a relative error of $10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.001 == approx(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.0000001 == approx(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to zero uses absolute error of $10^{-12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0001 == approx(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0000000000001 == approx(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate comparisons also work for composite data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1.000001, 3] == approx([1.000001, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'a': 1.000001, 'b': 3} == approx({'a': 1.000001, 'b': 3}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.000001, 3]) == approx(np.array([1.000001, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://docs.pytest.org/en/latest/reference.html#pytest-approx for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mocking\n",
    "\n",
    "- Temporarily replace a Python object with a different one, typically replacing a class or method\n",
    "- Supported by Python `unittest.mock`\n",
    "    - Relatively complex\n",
    "    - We will not use it directly\n",
    "    - For documentation, see\n",
    "        - https://docs.python.org/3/library/unittest.mock-examples.html\n",
    "        - https://docs.python.org/3/library/unittest.mock.html#the-mock-class\n",
    "- For convenient mocking with py.test, we need a py.test extension `pytest-mock`\n",
    "    - It should be installed in your `inf200` environment if you used the provided `requirements.txt`\n",
    "    - If not and you use conda, install with `conda install pytest-mock` (while you `inf200` enviroment is active)\n",
    "    - Otherwise install with `pip install pytest-mock` (while you `inf200` enviroment is active)\n",
    "    - For documentation, see https://github.com/pytest-dev/pytest-mock/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Replacing random generator with fixed value\n",
    "\n",
    "- See also `chutes_project/tests/test_player.py`\n",
    "- In the test below, `random.randint` is replaced by a function that always returns `1`. The modification is in force only in that test.\n",
    "\n",
    "```python\n",
    "def test_single_step_one(mocker):\n",
    "    mocker.patch('random.randint', return_value=1)\n",
    "    b = Board(chutes=[], ladders=[])\n",
    "    pl = Player(b)\n",
    "    pl.move()\n",
    "    assert pl.position == 1\n",
    "```\n",
    "\n",
    "- `mocker` is automatically provided by py.test if the `pytest-mock` extension is installed, no imports required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Counting the number of calls to a method\n",
    "\n",
    "- See `examples/biolab_project/biolab/tests/test_dish.py`\n",
    "\n",
    "```python\n",
    "class TestAgingCalls:\n",
    "    def test_dish_ages(self, mocker):\n",
    "        mocker.spy(Bacteria, 'ages')\n",
    "\n",
    "        n_a, n_b = 10, 20\n",
    "        d = Dish(n_a, n_b)\n",
    "        d.aging()\n",
    "\n",
    "        assert Bacteria.ages.call_count == n_a + n_b\n",
    "```\n",
    "\n",
    "- `mocker.spy()` wraps `Bacteria.ages` so we can extract information later\n",
    "- `Bacteria.ages.call_count` gives the number of times `Bacteria.ages` has been called\n",
    "- The \"spy\" has an effect only inside this test\n",
    "\n",
    "#### Example: Checking that all calls are made on different objects\n",
    "\n",
    "- See `test_dish.py` as well\n",
    "- Note that `Bacteria.ages()` is called with `self` as only argument\n",
    "\n",
    "```python\n",
    "class TestAgingCalls:\n",
    "    def test_dish_ages_callers(self, mocker):\n",
    "        mocker.spy(Bacteria, 'ages')\n",
    "\n",
    "        n_a, n_b = 10, 20\n",
    "        d = Dish(n_a, n_b)\n",
    "        d.aging()\n",
    "\n",
    "        args = Bacteria.ages.call_args_list\n",
    "        pos_args, kwargs = zip(*args)\n",
    "        assert len(set(pos_args)) == len(pos_args)\n",
    "```\n",
    "\n",
    "- `call_args_list` gives us the arguments for all calls to `ages`\n",
    "- The arguments are given as tuples `(positional arguments, keyword arguments)`\n",
    "- We are interested only in the positional arguments (`self`)\n",
    "- We want to check if each call was made for a different object\n",
    "    - `set(pos_args)` returns a set, containing only one instance of each element in `pos_args`\n",
    "    - if that set has the same size as `pos_args`, all elements of `pos_args` are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixtures\n",
    "\n",
    "- Set up or clean up things before/after a test\n",
    "- Parameterize tests: run one test several times with different values\n",
    "- For more information, see\n",
    "    - http://pytest.readthedocs.io/en/latest/fixture.html#fixture\n",
    "    - http://pytest.readthedocs.io/en/latest/parametrize.html#parametrize\n",
    "    - PyTest-related material at http://pythontesting.net/start-here/\n",
    "\n",
    "```python\n",
    "class TestDeathDivision:\n",
    "    \"\"\"\n",
    "    Tests for death and division.\n",
    "\n",
    "    The main point of this test class is to show the use of a fixture\n",
    "    to create an initial population before each test.\n",
    "    \"\"\"\n",
    "\n",
    "    @pytest.fixture(autouse=True)\n",
    "    def create_dish(self):\n",
    "        self.n_a = 10\n",
    "        self.n_b = 20\n",
    "        self.dish = Dish(self.n_a, self.n_b)\n",
    "\n",
    "    @pytest.fixture\n",
    "    def p_death_one(self):\n",
    "        # set death probability to 1 before test (setup)\n",
    "        Bacteria.set_params({'p_death': 1})\n",
    "        yield\n",
    "        \n",
    "        # code after yield executed after test (teardown)\n",
    "        Bacteria.set_params(Bacteria.default_params)\n",
    "\n",
    "    def test_death(self):\n",
    "        # test of fixture: do we have a \"fresh\" dish?\n",
    "        n_a_old = self.dish.get_num_a()\n",
    "        n_b_old = self.dish.get_num_b()\n",
    "        assert n_a_old == self.n_a\n",
    "        assert n_b_old == self.n_b\n",
    "\n",
    "        for _ in range(10):\n",
    "            self.dish.death()\n",
    "            n_a = self.dish.get_num_a()\n",
    "            n_b = self.dish.get_num_b()\n",
    "            assert n_a <= n_a_old\n",
    "            assert n_b <= n_b_old\n",
    "            n_a_old, n_b_old = n_a, n_b\n",
    "\n",
    "        # after 10 rounds of death probability of no change is minimal\n",
    "        assert self.dish.get_num_a() < self.n_a\n",
    "        assert self.dish.get_num_b() < self.n_b\n",
    "\n",
    "\n",
    "    def test_division(self):\n",
    "        # test of fixture: do we have a \"fresh\" dish?\n",
    "        n_a_old = self.dish.get_num_a()\n",
    "        n_b_old = self.dish.get_num_b()\n",
    "        assert n_a_old == self.n_a\n",
    "        assert n_b_old == self.n_b\n",
    "\n",
    "        for _ in range(10):\n",
    "            self.dish.division()\n",
    "            n_a = self.dish.get_num_a()\n",
    "            n_b = self.dish.get_num_b()\n",
    "            assert n_a >= n_a_old\n",
    "            assert n_b >= n_b_old\n",
    "            n_a_old, n_b_old = n_a, n_b\n",
    "\n",
    "        # after 10 rounds of death probability of no change is minimal\n",
    "        assert self.dish.get_num_a() > self.n_a\n",
    "        assert self.dish.get_num_b() > self.n_b\n",
    "\n",
    "    def test_all_die(self, p_death_one):\n",
    "        self.dish.death()\n",
    "        assert self.dish.get_num_a() == 0\n",
    "        assert self.dish.get_num_b() == 0\n",
    "\n",
    "    def test_zz_p_death_fine(self):\n",
    "        \"\"\"\n",
    "        Test to check that p_death modified only in test_all_die.\n",
    "        \"\"\"\n",
    "        assert Bacteria.p_death == Bacteria.default_params['p_death']\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"n_a, n_b, p_death\",\n",
    "                         [[100, 200, 0.1],\n",
    "                          [100, 200, 0.9],\n",
    "                          [10, 20, 0.5]])\n",
    "def test_death(n_a, n_b, p_death):\n",
    "    Bacteria.set_params({'p_death': p_death})\n",
    "    dish = Dish(n_a, n_b)\n",
    "    dish.death()\n",
    "    Bacteria.set_params(Bacteria.default_params)\n",
    "\n",
    "    died_a = n_a - dish.get_num_a()\n",
    "    died_b = n_b - dish.get_num_b()\n",
    "    assert binom_test(died_a, n_a, p_death) > ALPHA    # binom_test() from scipy.stats\n",
    "    assert binom_test(died_b, n_b, p_death) > ALPHA    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests and random selection\n",
    "\n",
    "- Test methods that depend on random numbers\n",
    "- Exact results will depend on precise sequence of random numbers generated, i.e., on the random generator used and the random seed\n",
    "\n",
    "### Basic approaches\n",
    "\n",
    "#### Fixed seed\n",
    "By seeding the random number generator with a fixed value, we can ensure that we always get the same sequence of random numbers; particularly important while debugging.\n",
    "\n",
    "- Requires that we know which random number generator is used by methods tested\n",
    "- Adding more tests or changing tests or code can change the way in which random numbers are consumed\n",
    "\n",
    "#### Mocking\n",
    "Mock the random number function to return a fixed value.\n",
    "\n",
    "- Allows us to check that the code using the random numbers works as expected\n",
    "- Does not test whether the result has the expected distribution\n",
    "\n",
    "#### Statistical tests\n",
    "\n",
    "- The principal approach is based on statistical testing of hypothesis\n",
    "    - Formulate a hypothesis (expectation), e.g., \"value $x$ is a sample of random variable $X$ which has a normal (Gaussian) distribution of given mean $\\mu$ and variance $\\sigma$\"\n",
    "    - Find the $p$-value of $x$, i.e., the probability to observe a value at least as far from the mean as $x$ if $x$ indeed follows the assumed distribution\n",
    "    - Compare the $p$-value to a predefined acceptance limit $\\alpha$: if $p>\\alpha$ the test is passed\n",
    "- Interpretation: Let, e.g., $\\alpha=0.01=1\\%$. If we observe a value $x$ with a $p$-value less than $\\alpha=1\\%$, this means that the value $x$ belongs to the outer tail of the assumed distribution, among those values that make up the 1% least likely values in the distribution. We thus assume that $x$ did not come from the expected distribution and declare the test failed.\n",
    "- Note: By construction, this test will fail in 1% of all cases even if $x$ follows the assumed distribution. Thus, failures need to be inspected carefully.\n",
    "- See, e.g., Knuth, The Art of Computer Programming, vol 2.\n",
    "\n",
    "#### Types of statistical tests\n",
    "\n",
    "- [$Z$-test](https://en.wikipedia.org/wiki/Z-test)\n",
    "    - Strictly speaking, tests whether the mean of $n$ random values drawn independently from the same distribution is from a Gaussian distribution of given mean and variance \n",
    "    - Due to the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem), it can also be applied in many other cases as an approximation provided we are considering averages of many trials\n",
    "    - If the variance of the Gaussian distribution is not know a priori, one should use [Student's $t$-test](https://en.wikipedia.org/wiki/Student%27s_t-test) instead\n",
    "\n",
    "- [Binomial test](https://en.wikipedia.org/wiki/Binomial_test)\n",
    "    - An explicit test for binomially distributed quantities, e.g., the number of successes in $n$ Bernoulli experiments (coin flips)\n",
    "    - See also [GraphPad](http://www.graphpad.com/guides/prism/6/statistics/index.htm?stat_binomial.htm) for an explanation of the test. The [binomial test in SciPy](http://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.binom.html) uses the same approach as GraphPad\n",
    "\n",
    "- `scipy.stats` provides [a number of statistical test functions](http://docs.scipy.org/doc/scipy-0.16.1/reference/stats.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
